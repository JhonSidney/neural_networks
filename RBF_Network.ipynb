{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jhon  RBF Network",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0GQWDGtrpX"
      },
      "source": [
        "# Rede Neural de Base Radial (RBF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7W_VNPAkFcO"
      },
      "source": [
        "As redes RBF são redes de alimentação direta (feedforward) consistindo de três camadas:\n",
        "\n",
        "\n",
        "1.   **Camada de entrada**: propaga os estímulos\n",
        "2.   **Camada escondida**: Unidades de processamento localmente sintonizáveis, utilizando mapeamento não linear.\n",
        "3.   **Camada de saída**: Unidades de processamento lineares.\n",
        "\n",
        "\n",
        "****\n",
        "\n",
        "**O treinamento dessa rede ocorre de forma híbrida**, combinando aprendizagem não supervisionada (ANS) com a supervisionada(AS). Isso ocorre, pois em geral não se sabe quais saídas se desejam para a camada escondida. Sendo assim, a distribuição de trabalhos ocorre:\n",
        "*   **ANS**: Treina a camada escondida definindo seus parâmetros livres (centros, larguras dos campos receptivos e pesos).\n",
        "*   **AS**: Determina os valores dos pesos entre as camadas escondidas e de saída, considerando constantes os parâmetros já definidos.\n",
        "\n",
        "\n",
        "****\n",
        "\n",
        "**O aprendizado consiste em** determinar os valores para:\n",
        "*   centro das funções de base radial,\n",
        "*   largura das funções,\n",
        "*   pesos da camada de saída.\n",
        "\n",
        "\n",
        "Além disso, para cada neurônio da camada escondida, ele computa uma função de base radial.\n",
        "\n",
        "\n",
        "Os passos necessários são:\n",
        "1.   Utilizar um algoritmo ANS para encontrar os centros (protótipo para um cluster) das RBF;\n",
        "2.   Utilizar métodos heurísticos para determinar a largura (área de influência de um cluster) de cada função;\n",
        "3.   Utilizar um AS para determinar os pesos da camada de saída da rede."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOIor4J3PFBL"
      },
      "source": [
        "1ª Etapa: Inicialização dos grupos com K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHWuP3AXjvq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a11aeae-dcf4-46a3-8142-894ab5bbb327"
      },
      "source": [
        "!git clone https://github.com/valmirf/redes_neurais_bcc.git"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'redes_neurais_bcc' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ulVaA8RPSwo"
      },
      "source": [
        "Definição da função de base radial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeqYYe9hPY4v"
      },
      "source": [
        "#função de base radial gaussiana\n",
        "#c = centro \n",
        "#s= largura\n",
        "#x = valor qualquer\n",
        "def rbfGaussiana(x, c, s):\n",
        "    return 1 / (np.sqrt((x-c)**2 + s **2 ))\n",
        "\n",
        "#função de cálculo da largura do campo receptivo em que se repete o mesmo valor pra todos os neurônios\n",
        "def computeEqualStds(centers,k):\n",
        "  stds = []\n",
        "  for c1 in centers:\n",
        "    dist = []\n",
        "    for c2 in centers:\n",
        "      if not np.array_equiv(c1,c2):\n",
        "        dist.append(np.sqrt(np.sum(c1-c2) ** 2))\n",
        "    dMin = np.min(dist)\n",
        "    stds.append(dMin/2)  \n",
        "  return np.array(stds)\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkrFhNWPLq41"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52oUNimoPuK3"
      },
      "source": [
        "2ª Etapa - Treinamento de uma Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGdrOhYfPzBu"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "class RBFNet(object):\n",
        "    \"\"\"Implementation of a Radial Basis Function Network\"\"\"\n",
        "\n",
        "    def __init__(self, k=4, attnumber=18, lr=0.01, epochs=100, rbf=rbfGaussiana, computeStds=computeEqualStds):\n",
        "        self.k = k  # grupos ou numero de neuronios na camada escondida\n",
        "        self.lr = lr # taxa de aprendizagem\n",
        "        self.epochs = epochs  # número de iterações\n",
        "        self.rbf = rbf # função de base radial\n",
        "        self.computeStds = computeStds  #função de cálculo da largura do campo receptivo\n",
        "\n",
        "\n",
        "        self.w = np.random.randn(self.k,attnumber)\n",
        "        self.b = np.random.randn(1)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.stds = []\n",
        "        #K-Means pra pegar os centros inicias \n",
        "        #1º parâmetro da rede RBF\n",
        "        kmeans = KMeans(\n",
        "            n_clusters=self.k, init='random',\n",
        "            n_init=10, max_iter=300).fit(X)\n",
        "        self.centers = kmeans.cluster_centers_\n",
        "        #print('centers: ', self.centers)\n",
        "        \n",
        "        #Cálculo la dargura do campo receptivo\n",
        "        #2º parâmetro da rede RBF\n",
        "        self.stds = self.computeStds(self.centers,self.k)\n",
        "        # training\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                # forward pass\n",
        "                #calcula a saída de cada neurônio da função de base radial\n",
        "                phi = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
        "                #calcula somatório do produto da saída da função de base radial e os pesos\n",
        "                F = phi.T.dot(self.w)\n",
        "                F = np.sum(F) + self.b\n",
        "                #saída da rede\n",
        "                out = self.sigmoid(F)\n",
        "                out = 0 if out < 0.5 else 1\n",
        "                \n",
        "                #função de perda \n",
        "                loss = (y[i] - out).flatten() ** 2\n",
        "                #print('Loss: {0:.2f}'.format(loss[0]))\n",
        "\n",
        "                #cálculo do erro\n",
        "                error = (y[i] - out).flatten()\n",
        "                #atualização dos pesos\n",
        "                #3º Parâmetro da rede \n",
        "                self.w = self.w + self.lr * error * phi \n",
        "                self.b = self.b + self.lr * error\n",
        "\n",
        "    #calcula saída da rede RBF com a rede treinada\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        error = 0\n",
        "        for i in range(X.shape[0]):\n",
        "            a = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
        "            F = a.T.dot(self.w)\n",
        "            #print('F: ' + str(F))\n",
        "            F = np.sum(F) + self.b\n",
        "            #print('F2: ' + str(F))\n",
        "            out = self.sigmoid(F)\n",
        "            out = 0 if out < 0.5 else 1\n",
        "            y_pred.append(out)\n",
        "\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    # Função de Ativação Sigmóide\n",
        "    def sigmoid(self, net):\n",
        "      return 1.0/(1.0+np.exp(-net))\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWNpEtxSW46Q"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Isto está formatado como código\n",
        "```\n",
        "\n",
        "# Executando a rede neural RBF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P75CdFJ4W7mU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9c3ec0a-1611-4312-ab9d-175481331fe4"
      },
      "source": [
        "# Neste código vou utilizar o pandas, framework amplamente utilizado pra lidar com dados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#carrega a base de dados e retorna conjuntos de treinamento e teste\n",
        "def load_data():\n",
        "    url = 'redes_neurais_bcc/SOM/iris.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    #remove a ultima coluna (dados)\n",
        "    data = df[df.columns[:-1]]\n",
        "    #normaliza os dados\n",
        "    normalized_data = (data - data.min()) / (data.max() - data.min())\n",
        "    #retorna a última coluna (rótulos)\n",
        "    labels = df[df.columns[-1]]\n",
        "    #separa em conjunto de treinamento e teste com seus respectivos rótulos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.2, random_state=0)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "#chama função que carrega base de dados\n",
        "training_inputs, test_inputs, training_labels, test_labels = load_data()\n",
        "\n",
        "#transforma rótulos do conjunto de treinamento em numeros pra calculo do erro\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(training_labels.values)\n",
        "training_labels_transformed = le.transform(training_labels.values)\n",
        "\n",
        "#chama RBF\n",
        "rbfnet = RBFNet(lr=1e-2, attnumber=4, k=5, computeStds=computeEqualStds)\n",
        "rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
        "\n",
        "#transforma rótulos do conjunto de teste em numeros pra calculo do erro\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(test_labels.values)\n",
        "test_labels_transformed = le.transform(test_labels.values)\n",
        "\n",
        "y_pred = rbfnet.predict(test_labels_transformed)\n",
        "errorabs = abs(test_labels_transformed-y_pred)\n",
        "\n",
        "print('error: ' + str(np.sum(errorabs)) + '/' + str(len(test_labels_transformed))) \n",
        "print('error: ', np.sum(errorabs)/len(test_labels_transformed)*100)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: 20/30\n",
            "error:  66.66666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLO2Gq4Jtso3"
      },
      "source": [
        "# Descrição Mini Projeto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOrl4i0areNo"
      },
      "source": [
        "**Utilizando o código acima, modifique a última seção (Executando com Base de Dados) para que ele seja executado com a base de dados do arquivo iris.csv.**\n",
        "\n",
        "\n",
        "## **1- Calcular a quantidade de neurônios escondidos:**\n",
        "\n",
        "## **a) 2**\n",
        "\n",
        "error: 20/30\n",
        "error:  66.66666666666666\n",
        "\n",
        "## **b) 3**\n",
        "\n",
        "error: 20/30\n",
        "error:  66.66666666666666\n",
        "\n",
        "## **c) 4**\n",
        "\n",
        "error: 20/30\n",
        "error:  66.66666666666666\n",
        "\n",
        "## **d) 5**\n",
        "\n",
        "error: 8/30\n",
        "error:  26.666666666666668\n",
        "\n",
        "\n",
        "## **Qual foi a melhor configuração? Avaliaria um outro valor?**\n",
        "\n",
        "A melhor configuração realizada foi com 5 e 6 neurônios, porém realizando a configuração com um número maior de neurônios acima ou abaixo dos valores anteriormente citados, ele comporta-se com resultados diferente dos neurônios 5 e 6 ou seja 66.66666 \n",
        "\n",
        "o outro valor avaliado foi com 6 neuronios\n",
        "\n",
        "## **2- Utilizando a melhor configuração da questão anterior, calcular a taxa de erro usando uma das outras maneiras de retorno da largura do campo receptivo da função de base radial. Altere o código de forma que cada neurônio possua sua própria largura.**\n",
        "\n",
        "Resposta: \n",
        "\n",
        "```\n",
        "error: 8/30\n",
        "error:  26.666666666666668\n",
        "\n",
        "#função de cálculo da largura do campo receptivo em que se repete o mesmo valor pra todos os neurônios\n",
        "def computeEqualStds(centers,k):\n",
        "  stds = []\n",
        "  for c1 in centers:\n",
        "    dist = []\n",
        "    for c2 in centers:\n",
        "      if not np.array_equiv(c1,c2):\n",
        "        dist.append(np.sqrt(np.sum(c1-c2) ** 2))\n",
        "    dMin = np.min(dist)\n",
        "    stds.append(dMin/2)  \n",
        "  return np.array(stds)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## **3- Modifique a função de base radial implementada (Gaussiana), para a Multiquadrática inversa e calcule a taxa de erro para as configurações das questões anteriores.**\n",
        "\n",
        "\n",
        "```\n",
        "def rbfGaussiana(x, c, s):\n",
        "    return 1 / (np.sqrt((x-c)**2 + s **2 ))\n",
        "\n",
        "\n",
        "error: 20/30\n",
        "error:  66.66666666666666\n",
        "\n",
        "```\n",
        "\n",
        "## **Qual foi a melhor configuração?**\n",
        "\n",
        "As melhores configurações apresentadas até o momento foram com os números de neurônios 5 e 6, com o resultado da função Gaussiana que apresentou o resultado bem abaixo dos valores dos neurônios 5 e 6 em relação a função Multiquadrática Inversa"
      ]
    }
  ]
}